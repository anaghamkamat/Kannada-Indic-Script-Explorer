
import re
import random
import unicodedata
from collections import Counter

# --- 1. Preprocessing & Normalization ---

def normalize_kannada(text):
    """
    Normalizes Kannada text by:
    1. Removing Zero-Width Joiners (ZWJ) and Non-Joiners (ZWNJ) commonly found in Indic text.
    2. Normalizing whitespace.
    3. Basic unicode normalization (NFC).
    """
    if not text: return ""
    
    # Unicode Normalization
    text = unicodedata.normalize('NFC', text)
    
    # Remove ZWJ/ZWNJ
    text = text.replace('\u200d', '').replace('\u200c', '')
    
    # Remove typical English punctuation if needed, keeping Kannada punctuations if any
    # For now, just basic strip
    text = text.strip()
    
    # Collapse multiple spaces
    text = re.sub(r'\s+', ' ', text)
    
    return text

def preprocess_text(text, remove_stopwords=False):
    """
    Tokenizes and optionally removes stopwords.
    """
    text = normalize_kannada(text)
    
    # Simple whitespace tokenization
    # In real world, we'd use a sentencepiece tokenizer or similar
    tokens = text.split(' ')
    
    if remove_stopwords:
        # A small sample list of Kannada stopwords
        stopwords = {
            '‡≤Æ‡≤§‡≥ç‡≤§‡≥Å', '‡≤í‡≤Ç‡≤¶‡≥Å', '‡≤à', '‡≤Ü', '‡≤®‡≤®‡≥ç‡≤®', '‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ', '‡≤Ö‡≤µ‡≤∞‡≥Å', '‡≤á‡≤¶‡≥Å', '‡≤Ü‡≤¶‡≤∞‡≥Ü', 
            '‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü', '‡≤®‡≤æ‡≤µ‡≥Å', '‡≤®‡≥Ä‡≤µ‡≥Å', '‡≤é‡≤Ç‡≤¶‡≥Å', '‡≤á‡≤¶‡≥Ü', '‡≤Ü‡≤ó‡≤ø', '‡≤Ö‡≤¶‡≥Å', '‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø', '‡≤á‡≤≤‡≥ç‡≤≤‡≤ø'
        }
        tokens = [t for t in tokens if t not in stopwords]
        
    return tokens

# --- 2. Classification (Rule Based) ---

def classify_text(text):
    """
    Classifies text into categories based on keyword presence.
    Categories: Sports, Politics, Cinema, Technology, General
    """
    keywords = {
        'Sports': ['‡≤ï‡≥ç‡≤∞‡≤ø‡≤ï‡≥Ü‡≤ü‡≥ç', '‡≤Ü‡≤ü', '‡≤¨‡≥ç‡≤Ø‡≤æ‡≤ü‡≤ø‡≤Ç‡≤ó‡≥ç', '‡≤¨‡≥å‡≤≤‡≤ø‡≤Ç‡≤ó‡≥ç', '‡≤™‡≤Ç‡≤¶‡≥ç‡≤Ø', '‡≤ï‡≥ç‡≤∞‡≥Ä‡≤°‡≥Ü', '‡≤ó‡≥Ü‡≤≤‡≥Å‡≤µ‡≥Å', '‡≤∏‡≥ã‡≤≤‡≥Å'],
        'Politics': ['‡≤ö‡≥Å‡≤®‡≤æ‡≤µ‡≤£‡≥Ü', '‡≤∏‡≤∞‡≥ç‡≤ï‡≤æ‡≤∞', '‡≤∞‡≤æ‡≤ú‡≤ï‡≥Ä‡≤Ø', '‡≤Æ‡≤Ç‡≤§‡≥ç‡≤∞‡≤ø', '‡≤™‡≤ï‡≥ç‡≤∑', '‡≤Æ‡≤§‡≤¶‡≤æ‡≤®', '‡≤™‡≥ç‡≤∞‡≤ß‡≤æ‡≤®‡≤ø'],
        'Cinema': ['‡≤ö‡≤≤‡≤®‡≤ö‡≤ø‡≤§‡≥ç‡≤∞', '‡≤®‡≤ü', '‡≤®‡≤ü‡≤ø', '‡≤∏‡≤ø‡≤®‡≤ø‡≤Æ‡≤æ', '‡≤π‡≤æ‡≤°‡≥Å', '‡≤®‡≤ø‡≤∞‡≥ç‡≤¶‡≥á‡≤∂‡≤ï', '‡≤§‡≥Ü‡≤∞‡≥Ü'],
        'Technology': ['‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤®', '‡≤ï‡≤Ç‡≤™‡≥ç‡≤Ø‡≥Ç‡≤ü‡≤∞‡≥ç', '‡≤Æ‡≥ä‡≤¨‡≥à‡≤≤‡≥ç', '‡≤ú‡≤æ‡≤≤‡≤§‡≤æ‡≤£', '‡≤∏‡≤æ‡≤´‡≥ç‡≤ü‡≥ç‡≤µ‡≥á‡≤∞‡≥ç', '‡≤Ö‡≤Ç‡≤§‡≤∞‡≥ç‡≤ú‡≤æ‡≤≤']
    }
    
    scores = {cat: 0 for cat in keywords}
    
    for token in text.split():
        for cat, words in keywords.items():
            if any(w in token for w in words):
                scores[cat] += 1
                
    # Get max score
    best_cat = max(scores, key=scores.get)
    if scores[best_cat] == 0:
        return "General / Unclassified"
    return best_cat

# --- 3. Sentiment Analysis (Lexicon Based) ---

def analyze_sentiment(text):
    """
    Returns polarity (-1 to 1) and label.
    """
    positive_words = [
        '‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü', '‡≤∏‡≥Å‡≤Ç‡≤¶‡≤∞', '‡≤â‡≤§‡≥ç‡≤§‡≤Æ', '‡≤∂‡≥ç‡≤∞‡≥á‡≤∑‡≥ç‡≤†', '‡≤ñ‡≥Å‡≤∑‡≤ø', '‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø', '‡≤ó‡≥Ü‡≤≤‡≥Å‡≤µ‡≥Å', '‡≤Ö‡≤¶‡≥ç‡≤≠‡≥Å‡≤§', 
        '‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø', '‡≤∏‡≤Ç‡≤§‡≥ã‡≤∑', '‡≤Ü‡≤®‡≤Ç‡≤¶', '‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç'
    ]
    negative_words = [
        '‡≤ï‡≥Ü‡≤ü‡≥ç‡≤ü', '‡≤ï‡≤∑‡≥ç‡≤ü', '‡≤¶‡≥Å‡≤É‡≤ñ', '‡≤®‡≥ã‡≤µ‡≥Å', '‡≤∏‡≥ã‡≤≤‡≥Å', '‡≤Ö‡≤∏‡≤π‡≥ç‡≤Ø', '‡≤ï‡≥ã‡≤™', '‡≤¨‡≥á‡≤ú‡≤æ‡≤∞‡≥Å', '‡≤≠‡≤Ø', 
        '‡≤¶‡≥ã‡≤∑', '‡≤∏‡≤Æ‡≤∏‡≥ç‡≤Ø‡≥Ü'
    ]
    
    score = 0
    words = text.split()
    for w in words:
        if any(p in w for p in positive_words):
            score += 1
        if any(n in w for n in negative_words):
            score -= 1
            
    # Normalize somewhat
    if score > 0: label = "Positive üòä"
    elif score < 0: label = "Negative üòû"
    else: label = "Neutral üòê"
    
    return label, score

# --- 4. Text Simplification (Demo) ---

def simplify_kannada(text):
    """
    Replaces complex/formal words with simpler colloquial ones.
    """
    replacements = {
        '‡≤µ‡≤ø‡≤¶‡≥ç‡≤Ø‡≤æ‡≤∞‡≥ç‡≤•‡≤ø': '‡≤Æ‡≤ï‡≥ç‡≤ï‡≤≥‡≥Å',       # Student -> Children (Contextual approx)
        '‡≤ö‡≤≤‡≤®‡≤ö‡≤ø‡≤§‡≥ç‡≤∞': '‡≤∏‡≤ø‡≤®‡≤ø‡≤Æ‡≤æ',        # Movie (Formal) -> Cinema
        '‡≤Ü‡≤∞‡≤ï‡≥ç‡≤∑‡≤ï': '‡≤™‡≥ä‡≤≤‡≥Ä‡≤∏‡≥ç',          # Police (Formal) -> Police
        '‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø': '‡≤°‡≤æ‡≤ï‡≥ç‡≤ü‡≤∞‡≥ç',          # Doctor (Formal) -> Doctor
        '‡≤¶‡≥Ç‡≤∞‡≤µ‡≤æ‡≤£‡≤ø': '‡≤´‡≥ã‡≤®‡≥ç',           # Telephone -> Phone
        '‡≤ó‡≥ç‡≤∞‡≤Ç‡≤•‡≤æ‡≤≤‡≤Ø': '‡≤≤‡≥à‡≤¨‡≥ç‡≤∞‡≤∞‡≤ø',       # Library -> Library
        '‡≤µ‡≤ø‡≤Æ‡≤æ‡≤® ‡≤®‡≤ø‡≤≤‡≥ç‡≤¶‡≤æ‡≤£': '‡≤è‡≤∞‡≥ç‚Äå‡≤™‡≥ã‡≤∞‡≥ç‡≤ü‡≥ç' # Airport
    }
    
    simple_text = text
    for complex_w, simple_w in replacements.items():
        simple_text = simple_text.replace(complex_w, simple_w)
        
    return simple_text

# --- 5. Data Generation (Mock) ---

def generate_story_start(prompt):
    """
    Mock story generator using predefined templates.
    """
    templates = [
        f"‡≤í‡≤Ç‡≤¶‡≤æ‡≤®‡≥ä‡≤Ç‡≤¶‡≥Å ‡≤ï‡≤æ‡≤≤‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø, {prompt} ‡≤é‡≤Ç‡≤¨ ‡≤ä‡≤∞‡≤ø‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤í‡≤¨‡≥ç‡≤¨ ‡≤∞‡≤æ‡≤ú‡≤®‡≤ø‡≤¶‡≥ç‡≤¶‡≤®‡≥Å. ‡≤Ö‡≤µ‡≤®‡≥Å ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø‡≤µ‡≤®‡≥Å...",
        f"‡≤Æ‡≥Å‡≤Ç‡≤ú‡≤æ‡≤®‡≥Ü ‡≤é‡≤¶‡≥ç‡≤¶ ‡≤ï‡≥Ç‡≤°‡≤≤‡≥á {prompt} ‡≤®‡≥ã‡≤°‡≤ø‡≤¶ ‡≤∞‡≤µ‡≤ø‡≤ó‡≥Ü ‡≤Ü‡≤∂‡≥ç‡≤ö‡≤∞‡≥ç‡≤Ø‡≤µ‡≤æ‡≤Ø‡≤ø‡≤§‡≥Å! ‡≤è‡≤ï‡≥Ü‡≤Ç‡≤¶‡≤∞‡≥Ü...",
        f"{prompt} ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤π‡≥á‡≤≥‡≤¨‡≥á‡≤ï‡≥Ü‡≤Ç‡≤¶‡≤∞‡≥Ü, ‡≤Ö‡≤¶‡≥Å ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤Ü‡≤∏‡≤ï‡≥ç‡≤§‡≤ø‡≤¶‡≤æ‡≤Ø‡≤ï‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤®‡≥Ç‡≤∞‡≤æ‡≤∞‡≥Å ‡≤µ‡≤∞‡≥ç‡≤∑‡≤ó‡≤≥ ‡≤π‡≤ø‡≤Ç‡≤¶‡≥Ü..."
    ]
    return random.choice(templates)

# --- 6. Translation (Mock Dictionary) ---

def basic_translate_en_kn(text):
    """
    Very basic word-level dictionary lookup.
    """
    dictionary = {
        'hello': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞',
        'world': '‡≤™‡≥ç‡≤∞‡≤™‡≤Ç‡≤ö',
        'love': '‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø',
        'kannada': '‡≤ï‡≤®‡≥ç‡≤®‡≤°',
        'good': '‡≤í‡≤≥‡≥ç‡≤≥‡≥Ü‡≤Ø',
        'morning': '‡≤Æ‡≥Å‡≤Ç‡≤ú‡≤æ‡≤®‡≥Ü/‡≤∂‡≥Å‡≤≠‡≥ã‡≤¶‡≤Ø',
        'is': '‡≤á‡≤¶‡≥Ü',
        'beautiful': '‡≤∏‡≥Å‡≤Ç‡≤¶‡≤∞',
        'name': '‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å',
        'my': '‡≤®‡≤®‡≥ç‡≤®'
    }
    
    words = text.lower().replace('.', '').split()
    translated = []
    for w in words:
        translated.append(dictionary.get(w, w)) # Return original if not found
        
    return " ".join(translated)
